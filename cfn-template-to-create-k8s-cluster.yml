AWSTemplateFormatVersion: 2010-09-09

Description: |
  This Cloudformation Template creates a Kubernetes Cluster on Ubuntu 20.04 of EC2 Instances.
  Security groups allows SSH (22) connections from anywhere.
  User needs to select appropriate key name when launching the template.
  This template is designed for us-east-1 (N. Virginia) region. 

# Parameters:
#   KeyPairName:
#     Description: Enter the name of your Key Pair for SSH connections.
#     Type: AWS::EC2::KeyPair::KeyName
#     ConstraintDescription: Must be one of the existing EC2 KeyPair

Resources:
  InstanceConnectPolicy:
    Type: "AWS::IAM::ManagedPolicy"
    Properties:
      PolicyDocument: #required
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - ec2-instance-connect:SendSSHPublicKey
            Resource:
              - !Sub arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:instance/*
            Condition: {"StringEquals": {"ec2:osuser": "ubuntu"}}
          - Effect: Allow
            Action:
              - ec2:DescribeInstances
            Resource: "*"
  
  EC2InstanceConnect:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service:
              - ec2.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      ManagedPolicyArns:
        - !Ref InstanceConnectPolicy
  EC2ConnectProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Roles: #required
        - !Ref EC2InstanceConnect
  ManagersSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Enable SSH for Kube Masters
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 30000
          ToPort: 32767
          CidrIp: 0.0.0.0/0        
  WorkersSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Enable SSH for Kube Workers
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 30000
          ToPort: 32767
          CidrIp: 0.0.0.0/0  
  ManagersSGIngress1:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !GetAtt ManagersSecurityGroup.GroupId
      IpProtocol: -1 #required
      SourceSecurityGroupId: !GetAtt ManagersSecurityGroup.GroupId
  ManagersSGIngress2:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !GetAtt ManagersSecurityGroup.GroupId
      IpProtocol: -1 #required
      SourceSecurityGroupId: !GetAtt WorkersSecurityGroup.GroupId
  WorkersSGIngress1:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !GetAtt WorkersSecurityGroup.GroupId
      IpProtocol: -1 #required
      SourceSecurityGroupId: !GetAtt WorkersSecurityGroup.GroupId
  WorkersSGIngress2:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !GetAtt WorkersSecurityGroup.GroupId
      IpProtocol: -1 #required
      SourceSecurityGroupId: !GetAtt ManagersSecurityGroup.GroupId

  KubeMaster1:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: ami-0149b2da6ceec4bb0
      InstanceType: t3a.medium
      KeyName: tyler-team #!Ref KeyPairName
      IamInstanceProfile: !Ref EC2ConnectProfile
      SecurityGroupIds:
        - !GetAtt ManagersSecurityGroup.GroupId
      Tags:                
        -                        
          Key: Name
          Value: !Sub Kube-Master${AWS::StackName}
      UserData: 
        Fn::Base64: 
          !Sub |
            #! /bin/bash
            apt-get update -y
            apt-get upgrade -y
            hostnamectl set-hostname kube-master
            chmod 777 /etc/sysctl.conf
            echo "net.ipv4.ip_forward=1" >> /etc/sysctl.conf
            sysctl -p
            chmod 644 /etc/sysctl.conf
            apt install -y docker.io
            systemctl start docker
            mkdir /etc/docker
            cat <<EOF | tee /etc/docker/daemon.json
            {
              "exec-opts": ["native.cgroupdriver=systemd"],
              "log-driver": "json-file",
              "log-opts": {
                "max-size": "100m"
              },
              "storage-driver": "overlay2"
            }
            EOF
            systemctl enable docker
            sudo systemctl daemon-reload
            sudo systemctl restart docker
            usermod -aG docker ubuntu
            newgrp docker
            apt install -y apt-transport-https
            curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube_latest_amd64.deb
            sudo dpkg -i minikube_latest_amd64.deb 
            minikube start
            sudo snap install kubectl --classic
            curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
            helm version

            # curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
            # apt-add-repository "deb http://apt.kubernetes.io/ kubernetes-xenial main"
            # apt update
            # apt install -y kubelet kubeadm kubectl
            # systemctl start kubelet
            # systemctl enable kubelet
            # kubeadm init --pod-network-cidr=172.16.0.0/16 --ignore-preflight-errors=All
            # mkdir -p /home/ubuntu/.kube
            # cp -i /etc/kubernetes/admin.conf /home/ubuntu/.kube/config
            # chown ubuntu:ubuntu /home/ubuntu/.kube/config
            # su - ubuntu -c 'kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml'


Outputs:
  1stKubeMasterPublicDNSName:
    Description: Kube Master 1st Public DNS Name
    Value: !Sub 
      - ${PublicAddress}
      - PublicAddress: !GetAtt KubeMaster1.PublicDnsName
  1stKubeMasterPrivateDNSName:
    Description: Kube Master 1st Private DNS Name
    Value: !Sub 
      - ${PrivateAddress}
      - PrivateAddress: !GetAtt KubeMaster1.PrivateDnsName
  